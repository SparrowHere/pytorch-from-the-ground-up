{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import (optim, nn)\n",
    "\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# User-defined classes\n",
    "from utils.base import (\n",
    "    LogisticRegression,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# User-defined functions\n",
    "from utils.preprocess import clusters, onehot\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.rcParams[\"font.family\"] = \"monospace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device has ben set to: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "SIZE = 100\n",
    "GENERATOR = torch.Generator().manual_seed(42)\n",
    "\n",
    "print(f\"Device has ben set to: {torch.cuda.get_device_properties(DEVICE).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = clusters(SIZE, means=[(-3, -3), (2, 2), (-2, 2)], stds=[0.8, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generated X:\", X, \"\\nGenerated y:\", y, sep='\\n')\n",
    "print(\"\\nShape of X: \", X.shape, \"\\nShape of y: \", y.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], marker='x', label='Cluster y = 0', s=20)\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], marker='+', label='Cluster y = 1', s=40)\n",
    "plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], marker='o', label='Cluster y = 2', s=20)\n",
    "plt.legend()\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Generated Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = onehot(y.int(), 3)\n",
    "print(f\"New y (One-Hot Encoded):\\n{y_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = LogisticRegression(in_dims=2, out_dims=3, multinomial=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = TensorDataset(X, y_encoded)\n",
    "Data.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, valData = random_split(Data, (0.8, 0.2), generator=GENERATOR)\n",
    "\n",
    "trainLoader = DataLoader(trainData, batch_size=BATCH_SIZE, generator=GENERATOR, shuffle=True)\n",
    "valLoader = DataLoader(valData, batch_size=BATCH_SIZE, generator=GENERATOR, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    Model,\n",
    "    trainLoader,\n",
    "    valLoader,\n",
    "    optimizer=optim.SGD(Model.parameters(), lr=.1),\n",
    "    criterion=nn.CrossEntropyLoss(reduction='mean'),        # Cross-entropy Loss (For classification)\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss = trainer.train(num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Loss:\", train_loss, \"\\nValidation Loss:\", val_loss, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    train_loss.keys(),\n",
    "    train_loss.values(),\n",
    "    label=\"Training Loss\"\n",
    ");\n",
    "plt.plot(\n",
    "    val_loss.keys(),\n",
    "    val_loss.values(),\n",
    "    color=\"orange\",\n",
    "    label=\"Validation Loss\"\n",
    ");\n",
    "plt.xticks(np.linspace(0, 20, 11));\n",
    "plt.grid(True, alpha = .6);\n",
    "plt.title(\"Training/Validation Loss\");\n",
    "plt.legend(loc='best');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicted Model Parameters:\", \"Weights: {}\".format(Model.linear.weight), \"Bias: {}\".format(Model.linear.bias), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shapes for Weight and Bias Tensors:\", Model.linear.weight.shape, Model.linear.bias.shape, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Model.linear.weight.detach().cpu().numpy()\n",
    "biases = Model.linear.bias.detach().cpu().numpy()\n",
    "\n",
    "Xmin, Xmax = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "ymin, ymax = X[:, 1].min() - .5, X[:, 1].max() + .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(Xmin, Xmax, SIZE), np.linspace(ymin, ymax, SIZE))\n",
    "grid = np.c_[xx.flatten(), yy.flatten()]\n",
    "\n",
    "scores = grid @ weights.T + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(scores, axis=1).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], marker='x', label='Cluster y = 0', s=20)\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], marker='+', label='Cluster y = 1', s=40)\n",
    "plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], marker='o', label='Cluster y = 2', s=20)\n",
    "\n",
    "plt.contourf(xx, yy, predicted_classes, alpha=0.2, cmap=plt.cm.coolwarm)\n",
    "\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title(\"Multinomial Classification Results\");\n",
    "plt.legend(loc='lower right');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on a New Instance\n",
    "Xn = torch.tensor([-3.77690, 0.007854], dtype=DTYPE, device='cpu').unsqueeze(0)\n",
    "print(f\"New Instance:\", Xn, Xn.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], marker='x', label='0th Class', s=20)\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], marker='+', label='1st Class', s=40)\n",
    "plt.scatter(X[y == 2][:, 0], X[y == 2][:, 1], marker='o', label='2nd Class', s=20)\n",
    "\n",
    "plt.contourf(xx, yy, predicted_classes, alpha=0.2, cmap=plt.cm.coolwarm)\n",
    "\n",
    "# New instance\n",
    "plt.scatter(Xn[:, 0], Xn[:, 1], marker='X', label=\"Example Instance\", s=100, c='black')\n",
    "\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title(\"Inferencing the Model on a New Instance\");\n",
    "plt.legend(loc='lower right');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn = Model(Xn.to(DEVICE))\n",
    "print(f\"Resulting predictions:\\n{yn}\")\n",
    "print(f\"Shape of prediction tensor: {yn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [f\"{prob.item() * 100:.2f}%\" for prob in yn.squeeze()]\n",
    "print(\"Probabilities:\", probs, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(yn, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
